{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DWw83AJkYjk"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6yqOQUGkYjn"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n2Qv6IcjmkCL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1mrs4idkYjn"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yDf1qvokYjo",
        "outputId": "6b6c5d95-eb36-4b65-efea-eaf5e885dd33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "X_train = X_train[:10000]\n",
        "y_train = y_train[:10000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdc7X2yQkYjq"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpmsafamkYjq"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "P0vdwEiakYjq",
        "outputId": "7903decf-9ecb-4bf3-d22d-4efca42ff990"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAml0lEQVR4nO3df3DUdX7H8dcmJJvE/MAQyY8SIEF+KRCn/qAUD1BSIM6oKL0DvbmC48noJVal1jvaO8C201x1RhkZDp3OHeideIAVHBzFIkioNtCR06N4kiNMPMKPhB+SbMiPzY/99g/GrSsgfD5u9pNsno+ZnWF3v698P/nmCy++2c07Ps/zPAEAEGMJrhcAABiYKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAgCtatWyefz6fPP/88/NiMGTM0Y8YMZ2sC+joKCADgBAUEAHCCAgIGoFAopI6ODtfLwABHAWFAWrFihXw+nw4ePKjvfe97yszM1JAhQ/TYY4+F/2H+/PPP5fP5tG7dugvyPp9PK1asMN7vyZMn9eCDDyo3N1cpKSkqKSnRyy+/HH6+q6tL2dnZeuCBBy7IBgIBpaSk6Mknnww/FgwGtXz5cl177bXy+/0qLCzUU089pWAweMF6Kyoq9Oqrr+r666+X3+/Xtm3bjNcPRNMg1wsAXPre976nkSNHqrKyUnv27NELL7ygs2fP6pVXXon6vtrb2zVjxgzV1taqoqJCRUVF2rRpkxYtWqSmpiY99thjSkpK0j333KM33nhDL730kpKTk8P5LVu2KBgMasGCBZLOX8Xcdddd+uCDD7R48WKNHz9e//u//6vnn39ef/zjH7Vly5aI/e/cuVMbN25URUWFcnJyNHLkyKh/joARDxiAli9f7kny7rrrrojHf/SjH3mSvN///vdeXV2dJ8lbu3btBXlJ3vLly8P3165d60ny6urqwo9Nnz7dmz59evj+ypUrPUneb37zm/BjnZ2d3pQpU7z09HQvEAh4nud57777rifJ27p1a8Q+77jjDq+4uDh8/9e//rWXkJDg/dd//VfEdi+++KInyfvwww8j1puQkOB9+umnlz02QKzwLTgMaOXl5RH3H330UUnS22+/HfV9vf3228rLy9N9990XfiwpKUl/+7d/q3PnzqmqqkqSdPvttysnJ0cbNmwIb3f27Flt375d8+fPDz+2adMmjR8/XuPGjdPp06fDt9tvv12S9P7770fsf/r06bruuuui/nkBtvgWHAa00aNHR9wfNWqUEhISIn6eJ1r+9Kc/afTo0UpIiPx/3/jx48PPS9KgQYM0b948rV+/XsFgUH6/X2+88Ya6uroiCujQoUP67LPPdM0111x0fydPnoy4X1RUFM1PB/jWKCDgK3w+30X//FU9PT29vo4FCxbopZde0jvvvKO5c+dq48aNGjdunEpKSsLbhEIhTZw4Uc8999xFP0ZhYWHE/dTU1F5dM2CKAsKAdujQoYgrg9raWoVCIY0cOVJXX321JKmpqSki8+WViqkRI0Zo//79CoVCEVdBBw8eDD//pWnTpik/P18bNmzQrbfeqp07d+of//EfIz7eqFGj9Pvf/14zZ868ZFkCfRmvAWFAW716dcT9VatWSZLKysqUmZmpnJwc7d69O2KbX/ziF1b7uuOOO9TQ0BDx2k53d7dWrVql9PR0TZ8+Pfx4QkKC/vqv/1pbt27Vr3/9a3V3d0d8+006/w6+Y8eO6d///d8v2Fd7e7taW1ut1gnECldAGNDq6up01113ac6cOaqurtZvfvMb3X///eFvdf3whz/Uz3/+c/3whz/UTTfdpN27d+uPf/yj1b4WL16sl156SYsWLdK+ffs0cuRIvf766/rwww+1cuVKZWRkRGw/f/58rVq1SsuXL9fEiRPDrxV96Qc/+IE2btyohx9+WO+//76mTp2qnp4eHTx4UBs3btS7776rm266ye7AADFAAWFA27Bhg5YtW6af/OQnGjRokCoqKvTss8+Gn1+2bJlOnTql119/XRs3blRZWZneeecdDR061Hhfqamp2rVrl37yk5/o5ZdfViAQ0NixY7V27VotWrTogu3/8i//UoWFhaqvr7/g6kc6f5W0ZcsWPf/883rllVe0efNmpaWlqbi4WI899pjGjBljvEYglnye53muFwHE2ooVK/T000/r1KlTysnJcb0cYEDiNSAAgBMUEADACQoIAOAErwEBAJzgCggA4AQFBABwos/9HFAoFNLx48eVkZHBeBEA6Ic8z1NLS4sKCgouGL77VX2ugI4fP37BEEUAQP9TX1+vYcOGXfL5PldAXx9Hgvhic1Vr8z4Z28nPa9asMc7U1NQYZ77pf4WX8uVwVBOffvqpcUaS1q5da5UDvupy/573WgGtXr1azz77rBoaGlRSUqJVq1bplltuuWyOb7vFt1gVkO15lJaWZpxJSUkxztgUkE2pfvVXevdFsTof4Mblvr698iaEDRs2aMmSJVq+fLl+97vfqaSkRLNnz77gF2QBAAauXimg5557Tg899JAeeOABXXfddXrxxReVlpamX/3qV72xOwBAPxT1Aurs7NS+fftUWlr6/ztJSFBpaamqq6sv2D4YDCoQCETcAADxL+oFdPr0afX09Cg3Nzfi8dzcXDU0NFywfWVlpbKyssI33gEHAAOD8x9EXbp0qZqbm8O3+vp610sCAMRA1N8Fl5OTo8TERDU2NkY83tjYqLy8vAu29/v98vv90V4GAKCPi/oVUHJysm688Ubt2LEj/FgoFNKOHTs0ZcqUaO8OANBP9crPAS1ZskQLFy7UTTfdpFtuuUUrV65Ua2urHnjggd7YHQCgH+qVApo/f75OnTqlZcuWqaGhQTfccIO2bdt2wRsTAAADV5/7fUCBQEBZWVmulxF1sfqJ78TERONMKBQyzkh9+yfSH3zwQavcypUrjTN/8zd/Y5yxmZ4wcuRI48z06dONM5I0Z84cq1xfZfP3QpJ6enqivJKBpbm5WZmZmZd83vm74AAAAxMFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnGAYqYVYDRaNR8OGDTPOfPe73zXOTJs2zTgjSddee61x5uDBg8aZ//zP/zTOFBcXG2dGjRplnJGkhATz/5s+++yzxpm9e/caZ9B/MIwUANAnUUAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4MQg1wuAew888IBV7oknnjDOFBYWGmfq6+uNM8Fg0DgjSZ2dncaZnJwc40xTU5NxJjs72zhz2223GWckqaenxzhTUlJinPH7/caZ7du3G2eee+4544wkffrpp1Y5XBmugAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACZ/neZ7rRXxVIBBQVlaW62X0W3v37jXO2B7v5uZm40x7e7txxmaw6JAhQ4wzktTV1WWcGTFihHHGZtinzdfp9OnTxhlJOnv2rHGmo6PDODNokPk85IyMjJhkJOn11183ztgM6Y1Xzc3NyszMvOTzXAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMMI7Xg8/mMMzaH+Z577jHO/Ou//qtx5tixY8YZSUpOTjbO2Bw7m8GdNmuT7IZjdnd3G2dGjx5tnDl69KhxxmaQqySlpaUZZ9ra2owziYmJxhmbv0sJCXb/17766quNM2PHjjXO2JxD/QHDSAEAfRIFBABwIuoFtGLFCvl8vojbuHHjor0bAEA/Z/4N7ytw/fXX67333vv/nVh8Xx0AEN96pRkGDRqkvLy83vjQAIA40SuvAR06dEgFBQUqLi7W97//fR05cuSS2waDQQUCgYgbACD+Rb2AJk+erHXr1mnbtm1as2aN6urq9J3vfEctLS0X3b6yslJZWVnhW2FhYbSXBADog6JeQGVlZfrud7+rSZMmafbs2Xr77bfV1NSkjRs3XnT7pUuXqrm5OXyrr6+P9pIAAH1Qr787YPDgwRozZoxqa2sv+rzf75ff7+/tZQAA+phe/zmgc+fO6fDhw8rPz+/tXQEA+pGoF9CTTz6pqqoqff755/rv//5v3XPPPUpMTNR9990X7V0BAPqxqH8L7ujRo7rvvvt05swZXXPNNbr11lu1Z88eXXPNNdHeFQCgH2MYaR+2fft244zN8MRz584ZZyS7waI2QyFtfpDZ9rS2eT2yubnZOGNzHNLT040ztq+vnj592ipnasiQIcaZ1tZW40woFDLOSNKYMWOMM8uWLTPOrFmzxjjTHzCMFADQJ1FAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADAiV7/hXSwl5aWZpyxGdRoO7gzMTHROGMzWNTmc0pNTTXOSLEbEpqTk2OcOXbsmHHGdhhpe3u7caa7u9s4Y3McOjo6YrIfSerp6THO2PzqmXgdRno5XAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACaZhx8jMmTONM1dddZVxpqmpyThjOw3bhs2UZZsJ1YFAwDgjSV988YVxJi8vzzhjcxxs2EwSl6QhQ4YYZ2y+Tjbnns1E9YyMDOOMZHf8xo8fb7WvgYgrIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwgmGkMTJ16tSY7CclJcU409bWZrWvnp4e48yxY8eMM9nZ2caZUChknJGkpKQk44zNcbAZemoz7DOWEhMTjTPBYNA4YzPA1OYckqSjR48aZ9LT0632NRD17TMaABC3KCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEw0hjZMqUKcaZ7u5u48ygQeZfUpsBnJLU1dVlnBk5cqRxJjk52ThjM7BSshv4aXMcbNiszXYoqw2/32+cidU5bjMoVbIbNGuzvoGKKyAAgBMUEADACeMC2r17t+68804VFBTI5/Npy5YtEc97nqdly5YpPz9fqampKi0t1aFDh6K1XgBAnDAuoNbWVpWUlGj16tUXff6ZZ57RCy+8oBdffFF79+7VVVddpdmzZ6ujo+NbLxYAED+MXy0rKytTWVnZRZ/zPE8rV67UT3/6U919992SpFdeeUW5ubnasmWLFixY8O1WCwCIG1F9Daiurk4NDQ0qLS0NP5aVlaXJkyerurr6oplgMKhAIBBxAwDEv6gWUENDgyQpNzc34vHc3Nzwc19XWVmprKys8K2wsDCaSwIA9FHO3wW3dOlSNTc3h2/19fWulwQAiIGoFlBeXp4kqbGxMeLxxsbG8HNf5/f7lZmZGXEDAMS/qBZQUVGR8vLytGPHjvBjgUBAe/futZoEAACIX8bvgjt37pxqa2vD9+vq6vTJJ58oOztbw4cP1+OPP65/+Zd/0ejRo1VUVKSf/exnKigo0Ny5c6O5bgBAP2dcQB999JFuu+228P0lS5ZIkhYuXKh169bpqaeeUmtrqxYvXqympibdeuut2rZtm1JSUqK3agBAv+fzbKc29pJAIKCsrCzXy4i6r141Xqmvv5Z2JWxeQ2tpaTHOSLL64WKbgZo2p6jt8Emfz2eVM2WzvlgOSrUZqJmenm6caWpqMs6kpaUZZ6677jrjjCR99tlnxpkbbrjBOFNQUGCcudQ7i/uS5ubmb/w3yfm74AAAAxMFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOmI+8hdXUX5sJ38ePHzfOpKamGmfOnTtnnJHsplR3d3cbZ/x+v3HGls3EaZsJ2j09PTHZj81Ua9t9ZWRkGGfOnDljnLH51S7t7e3GGUn64osvjDM2x27MmDHGmf4wDftyuAICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcYRmrhhhtuMM7YDLlMSkoyzgSDQeOMzdoku0GXNsNIbdYXCoWMM7Zshk/Gaj+2a+vs7DTO2HydbAaLJiYmGmds/l5IdkNjbTKZmZnGmXjAFRAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOMEwUgsTJkwwzsRqkKTNEM7s7GzjjCQdPXrUKhcLnudZ5bq6uowzycnJxhmbgZo254PtoFmb88hm0KzNMFKb42Az2Fey+9raHLusrCzjTDzgCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnGAYqYXCwkLjTEdHh3HGZjDmoEHmX9L/+I//MM5I0l/91V8ZZ86ePWucsRncaTMQ0nZfNgM/bdbX09NjnLEdwmnzOQWDQeOMzTDS1NRU40xnZ6dxRrL7nGy+TjafUzzgCggA4AQFBABwwriAdu/erTvvvFMFBQXy+XzasmVLxPOLFi2Sz+eLuM2ZMyda6wUAxAnjAmptbVVJSYlWr159yW3mzJmjEydOhG+vvfbat1okACD+GL9iXVZWprKysm/cxu/3Ky8vz3pRAID41yuvAe3atUtDhw7V2LFj9cgjj+jMmTOX3DYYDCoQCETcAADxL+oFNGfOHL3yyivasWOH/u3f/k1VVVUqKyu75FsTKysrlZWVFb7ZvMUZAND/RP3ngBYsWBD+88SJEzVp0iSNGjVKu3bt0syZMy/YfunSpVqyZEn4fiAQoIQAYADo9bdhFxcXKycnR7W1tRd93u/3KzMzM+IGAIh/vV5AR48e1ZkzZ5Sfn9/buwIA9CPG34I7d+5cxNVMXV2dPvnkE2VnZys7O1tPP/205s2bp7y8PB0+fFhPPfWUrr32Ws2ePTuqCwcA9G/GBfTRRx/ptttuC9//8vWbhQsXas2aNdq/f79efvllNTU1qaCgQLNmzdI///M/y+/3R2/VAIB+z7iAZsyYIc/zLvn8u++++60W1B/YDA60GSx61VVXxWQ/77zzjnFGkn7wgx8YZ06dOmWc+abzrS+wWZ/NwEqbAaE2GdtcW1ubcaagoMA4YzPYt7293Tgj2Q1ztTkfbIYIxwNmwQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMCJgTmC9VtqbW01zvh8vphkEhMTjTPBYNA4Y8t2OnNfFqtp3bE6hyS76cw207BzcnKMM2+99ZZxprCw0Dgj2U2+t5l0brOfeBB//xoAAPoFCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADjBMFILJ0+eNM7YDIXs6OgwzgwePNg409XVZZyRpFAoZJyxGUYaq2GftmL1OdkMubQ9djbDMZubm40zNkNPjxw5YpzJzs42zkhSenq6ccbmmMfjkN4rMTA/awCAcxQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwgmGkFk6dOmWcSUlJMc7YDDC1EQwGrXI2AxRtPqdYDiON1WDRxMRE44zN8NfOzk7jjCRlZmYaZ2L1dfr888+NM8XFxVb7ys3NNc50d3cbZ2wGzcYDroAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAmGkVr44osvjDNJSUm9sJIL2QyftBmeaMtm2KdNxna4Y6wGwMaK7de2q6vLOGMzwLS9vd0409LSYpxpa2szzkixGxqbnJxsnIkHXAEBAJyggAAAThgVUGVlpW6++WZlZGRo6NChmjt3rmpqaiK26ejoUHl5uYYMGaL09HTNmzdPjY2NUV00AKD/MyqgqqoqlZeXa8+ePdq+fbu6uro0a9Ystba2hrd54okntHXrVm3atElVVVU6fvy47r333qgvHADQvxm9CWHbtm0R99etW6ehQ4dq3759mjZtmpqbm/XLX/5S69ev1+233y5JWrt2rcaPH689e/boL/7iL6K3cgBAv/atXgNqbm6WJGVnZ0uS9u3bp66uLpWWloa3GTdunIYPH67q6uqLfoxgMKhAIBBxAwDEP+sCCoVCevzxxzV16lRNmDBBktTQ0KDk5GQNHjw4Ytvc3Fw1NDRc9ONUVlYqKysrfCssLLRdEgCgH7EuoPLych04cEC//e1vv9UCli5dqubm5vCtvr7+W308AED/YPWDqBUVFXrrrbe0e/duDRs2LPx4Xl6eOjs71dTUFHEV1NjYqLy8vIt+LL/fL7/fb7MMAEA/ZnQF5HmeKioqtHnzZu3cuVNFRUURz994441KSkrSjh07wo/V1NToyJEjmjJlSnRWDACIC0ZXQOXl5Vq/fr3efPNNZWRkhF/XycrKUmpqqrKysvTggw9qyZIlys7OVmZmph599FFNmTKFd8ABACIYFdCaNWskSTNmzIh4fO3atVq0aJEk6fnnn1dCQoLmzZunYDCo2bNn6xe/+EVUFgsAiB9GBeR53mW3SUlJ0erVq7V69WrrRfV1R44cMc5cybH7OpvBmIMGxW6+rM2QUJtBjTb7sWUzfDJWX9tYshlqa/Nars1xOHbsmHEmGAwaZyS7IcI2A2AZRgoAQAxRQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgROxGJ8eRL38Pkomurq5eWMmFbKY527KZ+mszOTpWU7dt2ezLZmp5rI6dFLuJzikpKcaZjo4O40xLS4txRrL7+9TT02OcYRo2AAAxRAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnGEZqoampyTgTDAajv5CL8Pl8xpmsrCyrfdkMx0xKSjLO2AzutDkOtjmbjO2Q0Fjtx2agZmdnp9W+TNl8To2NjVb7Sk1NNc60tbUZZ9LS0owz8YArIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwgmGkMfKHP/zBODN48GDjjM3QxREjRhhnbMVqYKXtMFIbiYmJxhmbQa7d3d3GGZuhopLk9/uNM2fOnLHalymbYaQtLS1W+0pOTjbOnDx50jhjcz7EA66AAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJhpHGiM0w0rlz5xpnvvjiC+NMU1OTccaWzSBJm4GatkM4bYZC2gxYtRn2mZSUZJyxOd5S7Aas2jh79qxx5vDhw1b7OnHihHHG5tyz+XsbD7gCAgA4QQEBAJwwKqDKykrdfPPNysjI0NChQzV37lzV1NREbDNjxgz5fL6I28MPPxzVRQMA+j+jAqqqqlJ5ebn27Nmj7du3q6urS7NmzVJra2vEdg899JBOnDgRvj3zzDNRXTQAoP8zehPCtm3bIu6vW7dOQ4cO1b59+zRt2rTw42lpacrLy4vOCgEAcelbvQbU3NwsScrOzo54/NVXX1VOTo4mTJigpUuXqq2t7ZIfIxgMKhAIRNwAAPHP+m3YoVBIjz/+uKZOnaoJEyaEH7///vs1YsQIFRQUaP/+/frxj3+smpoavfHGGxf9OJWVlXr66adtlwEA6KesC6i8vFwHDhzQBx98EPH44sWLw3+eOHGi8vPzNXPmTB0+fFijRo264OMsXbpUS5YsCd8PBAIqLCy0XRYAoJ+wKqCKigq99dZb2r17t4YNG/aN206ePFmSVFtbe9EC8vv9Vj+UBwDo34wKyPM8Pfroo9q8ebN27dqloqKiy2Y++eQTSVJ+fr7VAgEA8cmogMrLy7V+/Xq9+eabysjIUENDgyQpKytLqampOnz4sNavX6877rhDQ4YM0f79+/XEE09o2rRpmjRpUq98AgCA/smogNasWSPp/A+bftXatWu1aNEiJScn67333tPKlSvV2tqqwsJCzZs3Tz/96U+jtmAAQHww/hbcNyksLFRVVdW3WhAAYGBgGnaMfH1k0ZU4d+6ccSY1NdU4c+DAAeOMJKt3K359asaVsJmynJycbJyRJJ/PZ5xJS0szzgwaZP5XLz093ThjOw3bZn2xep23sbHROHPq1CmrfY0ZM8Y4c/z48Zhk4gHDSAEATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACZ9nM+mxFwUCAWVlZbleBq7A1q1bjTM2Q0Jthn3ash3eaSoUCsVkP7a6u7uNM11dXcYZm9+GPH36dOOMrerqauNMSkqKcaasrMw48+XvY+vLmpublZmZecnnuQICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABODHK9gK/rY6Pp8A3a2tqMMzbzwmJ5TjAL7rxYzYKz2U8stba2GmdsPqe+fj7Yutzf3T43jPTo0aMqLCx0vQwAwLdUX1+vYcOGXfL5PldAoVBIx48fV0ZGhnw+X8RzgUBAhYWFqq+v/8YJq/GO43Aex+E8jsN5HIfz+sJx8DxPLS0tKigo+MbvKvS5b8ElJCR8Y2NKUmZm5oA+wb7EcTiP43Aex+E8jsN5ro/DlfxaHd6EAABwggICADjRrwrI7/dr+fLlVr9FMZ5wHM7jOJzHcTiP43BefzoOfe5NCACAgaFfXQEBAOIHBQQAcIICAgA4QQEBAJyggAAATvSbAlq9erVGjhyplJQUTZ48Wf/zP//jekkxt2LFCvl8vojbuHHjXC+r1+3evVt33nmnCgoK5PP5tGXLlojnPc/TsmXLlJ+fr9TUVJWWlurQoUNuFtuLLnccFi1adMH5MWfOHDeL7SWVlZW6+eablZGRoaFDh2ru3LmqqamJ2Kajo0Pl5eUaMmSI0tPTNW/ePDU2Njpace+4kuMwY8aMC86Hhx9+2NGKL65fFNCGDRu0ZMkSLV++XL/73e9UUlKi2bNn6+TJk66XFnPXX3+9Tpw4Eb598MEHrpfU61pbW1VSUqLVq1df9PlnnnlGL7zwgl588UXt3btXV111lWbPnq2Ojo4Yr7R3Xe44SNKcOXMizo/XXnsthivsfVVVVSovL9eePXu0fft2dXV1adasWRFTq5944glt3bpVmzZtUlVVlY4fP657773X4aqj70qOgyQ99NBDEefDM88842jFl+D1A7fccotXXl4evt/T0+MVFBR4lZWVDlcVe8uXL/dKSkpcL8MpSd7mzZvD90OhkJeXl+c9++yz4ceampo8v9/vvfbaaw5WGBtfPw6e53kLFy707r77bifrceXkyZOeJK+qqsrzvPNf+6SkJG/Tpk3hbT777DNPklddXe1qmb3u68fB8zxv+vTp3mOPPeZuUVegz18BdXZ2at++fSotLQ0/lpCQoNLSUlVXVztcmRuHDh1SQUGBiouL9f3vf19HjhxxvSSn6urq1NDQEHF+ZGVlafLkyQPy/Ni1a5eGDh2qsWPH6pFHHtGZM2dcL6lXNTc3S5Kys7MlSfv27VNXV1fE+TBu3DgNHz48rs+Hrx+HL7366qvKycnRhAkTtHTpUqvf4dWb+tw07K87ffq0enp6lJubG/F4bm6uDh486GhVbkyePFnr1q3T2LFjdeLECT399NP6zne+owMHDigjI8P18pxoaGiQpIueH18+N1DMmTNH9957r4qKinT48GH9wz/8g8rKylRdXa3ExETXy4u6UCikxx9/XFOnTtWECRMknT8fkpOTNXjw4Iht4/l8uNhxkKT7779fI0aMUEFBgfbv368f//jHqqmp0RtvvOFwtZH6fAHh/5WVlYX/PGnSJE2ePFkjRozQxo0b9eCDDzpcGfqCBQsWhP88ceJETZo0SaNGjdKuXbs0c+ZMhyvrHeXl5Tpw4MCAeB30m1zqOCxevDj854kTJyo/P18zZ87U4cOHNWrUqFgv86L6/LfgcnJylJiYeMG7WBobG5WXl+doVX3D4MGDNWbMGNXW1rpeijNfngOcHxcqLi5WTk5OXJ4fFRUVeuutt/T+++9H/P6wvLw8dXZ2qqmpKWL7eD0fLnUcLmby5MmS1KfOhz5fQMnJybrxxhu1Y8eO8GOhUEg7duzQlClTHK7MvXPnzunw4cPKz893vRRnioqKlJeXF3F+BAIB7d27d8CfH0ePHtWZM2fi6vzwPE8VFRXavHmzdu7cqaKioojnb7zxRiUlJUWcDzU1NTpy5EhcnQ+XOw4X88knn0hS3zofXL8L4kr89re/9fx+v7du3TrvD3/4g7d48WJv8ODBXkNDg+ulxdTf/d3febt27fLq6uq8Dz/80CstLfVycnK8kydPul5ar2ppafE+/vhj7+OPP/Ykec8995z38ccfe3/60588z/O8n//8597gwYO9N99809u/f7939913e0VFRV57e7vjlUfXNx2HlpYW78knn/Sqq6u9uro677333vP+/M//3Bs9erTX0dHheulR88gjj3hZWVnerl27vBMnToRvbW1t4W0efvhhb/jw4d7OnTu9jz76yJsyZYo3ZcoUh6uOvssdh9raWu+f/umfvI8++sirq6vz3nzzTa+4uNibNm2a45VH6hcF5Hmet2rVKm/48OFecnKyd8stt3h79uxxvaSYmz9/vpefn+8lJyd7f/Znf+bNnz/fq62tdb2sXvf+++97ki64LVy40PO882/F/tnPfubl5uZ6fr/fmzlzpldTU+N20b3gm45DW1ubN2vWLO+aa67xkpKSvBEjRngPPfRQ3P0n7WKfvyRv7dq14W3a29u9H/3oR97VV1/tpaWleffcc4934sQJd4vuBZc7DkeOHPGmTZvmZWdne36/37v22mu9v//7v/eam5vdLvxr+H1AAAAn+vxrQACA+EQBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE78H1KKlHkwbdkBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "plt.imshow(X_train[idx], cmap='gray')\n",
        "plt.title(format(label_class[y_train[idx]]))\n",
        "plt.axis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXeV8KW3kYjr"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtos2kj8kYjr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jP7rg_jkYjr"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "O4ElfVnDkYjr"
      },
      "outputs": [],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "\n",
        "X_train_norm = X_train / 255.0\n",
        "X_test_norm = X_test / 255.0\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "X_train_norm = X_train_norm.reshape(-1, 784)\n",
        "X_test_norm = X_test_norm.reshape(-1, 784)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OygC92P8kYjs"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jmo_6xI5kYjs"
      },
      "outputs": [],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMfj5NGkkYjs"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVzG9fUbkYjs",
        "outputId": "a8e5bb41-1ee5-4b6f-8d4c-0389adc15542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 1s 3ms/step - loss: 1.7864 - accuracy: 0.3580\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 1.1248 - accuracy: 0.6276\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8537 - accuracy: 0.6965\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.7384\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7738\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7964\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.8116\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8217\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8269\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8306\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8358\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8375\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8441\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8432\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8429\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8457\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8525\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8545\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8552\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8566\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8567\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8585\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8611\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8630\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8637\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8646\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8658\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8680\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8679\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8703\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8731\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8714\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8724\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8747\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8730\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8779\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8756\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8788\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8768\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8766\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8808\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8826\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8835\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8830\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8833\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8834\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8804\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8860\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8856\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8890\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8903\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8917\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8911\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8905\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8916\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8901\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8884\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8913\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8940\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8959\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8953\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8907\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8980\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8980\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8973\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8973\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8992\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8952\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8991\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9025\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.9008\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.9044\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.9067\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.9028\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9032\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.9030\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9031\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.9069\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.9042\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.9027\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.9048\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9055\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.9075\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9101\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9072\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.9049\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9078\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9106\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9065\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.9127\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9130\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9100\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9090\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.9100\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.9135\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9144\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.9135\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.9138\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9158\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bee148c2980>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jXxSACLkYjt"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0IrmJzOkYjt",
        "outputId": "174904fc-8f95-4881-cd0f-a244df49b6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.9146000146865845\n",
            "accuracy on test with NN: 0.8324000239372253\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBy2A55ikYjt"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9xqHhgLkYju"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgjagYc3kYju"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TOvQHGzHkYju"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2vm57GtkYju",
        "outputId": "5e99174e-a0d7-4ba9-ac7d-1cf7880e0718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.8329\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on train', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_8ysKPQkYju"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMETohsvkYjv"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}