{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we master the preprocessing, let's make our first Bag Of Words (BOW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse our dataset of Coldplay songs to make a BOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK and all the needed libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset in *coldplay.csv* using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Artist                           Song  \\\n",
      "0  Coldplay                 Another's Arms   \n",
      "1  Coldplay                Bigger Stronger   \n",
      "2  Coldplay                       Daylight   \n",
      "3  Coldplay                       Everglow   \n",
      "4  Coldplay  Every Teardrop Is A Waterfall   \n",
      "\n",
      "                                                Link  \\\n",
      "0            /c/coldplay/anothers+arms_21079526.html   \n",
      "1          /c/coldplay/bigger+stronger_20032648.html   \n",
      "2                 /c/coldplay/daylight_20032625.html   \n",
      "3                 /c/coldplay/everglow_21104546.html   \n",
      "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
      "\n",
      "                                              Lyrics  \n",
      "0  Late night watching tv  \\nUsed to be you here ...  \n",
      "1  I want to be bigger stronger drive a faster ca...  \n",
      "2  To my surprise, and my delight  \\nI saw sunris...  \n",
      "3  Oh, they say people come  \\nThey say people go...  \n",
      "4  I turn the music up, I got my records on  \\nI ...  \n"
     ]
    }
   ],
   "source": [
    "# TODO: Load the dataset in coldplay.csv\n",
    "df = pd.read_csv(\"coldplay.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know this dataset, but you can check it again if you want to refresh your memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Artist  120 non-null    object\n",
      " 1   Song    120 non-null    object\n",
      " 2   Link    120 non-null    object\n",
      " 3   Lyrics  120 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the *CountVectorizer* of scikit-learn, make a BOW of all the lyrics of Coldplay, and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 1569)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute a BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1569, stop_words='english')\n",
    "bow_matrix = vectorizer.fit_transform(df['Lyrics'])\n",
    "bow_shape = bow_matrix.shape\n",
    "print(bow_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the BOW matrix, we would like to have a new dataframe having the BOW for each song, and as columns the corresponding words (just as we did in the lecture at the end).\n",
    "\n",
    "So that at the end we would end up with a dataframe containing something like the following (120 raws for 120 songs, and as many columns as words):\n",
    "\n",
    "| | ah | adventure | ... | yeah \n",
    "|---|---|---|---|---| \n",
    "| 0 | 0 | 1 | ... | 4 |\n",
    "| 1 | 8 | 0 | ... | 2 |\n",
    "|...|...|...|...|...|\n",
    "| 119 | 5 | 0 | ... | 8 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10  2000  2gether  76543  aaaaaah  aaaaah  aaaah  achin  adventure  \\\n",
      "0     0     0        0      0        0       0      0      0          0   \n",
      "1     0     0        0      0        0       0      0      0          0   \n",
      "2     0     0        0      0        0       0      0      0          0   \n",
      "3     0     0        0      0        0       0      0      0          0   \n",
      "4     0     0        0      0        0       0      0      0          0   \n",
      "..   ..   ...      ...    ...      ...     ...    ...    ...        ...   \n",
      "115   0     0        0      0        0       0      0      0          0   \n",
      "116   0     0        0      0        0       0      0      0          0   \n",
      "117   0     0        1      0        0       0      0      0          0   \n",
      "118   0     0        0      0        0       0      0      0          0   \n",
      "119   0     0        0      0        0       0      0      0          0   \n",
      "\n",
      "     advice  ...  x2  x7  ya  yeah  years  yellow  yes  yesterday  young  \\\n",
      "0         0  ...   0   0   0     0      0       0    0          0      0   \n",
      "1         0  ...   0   0   0     0      0       0    0          0      0   \n",
      "2         0  ...   0   0   0     2      0       0    0          0      0   \n",
      "3         0  ...   0   0   0     2      0       0    0          0      0   \n",
      "4         0  ...   0   0   0     0      0       0    0          0      0   \n",
      "..      ...  ...  ..  ..  ..   ...    ...     ...  ...        ...    ...   \n",
      "115       0  ...   0   0   0     0      0       0    0          0      0   \n",
      "116       0  ...   0   0   0    11      0       0    0          0      0   \n",
      "117       0  ...   0   0   0     3      0       0    0          0      0   \n",
      "118       0  ...   0   0   0     0      0       0    0          0      0   \n",
      "119       0  ...   0   0   0     0      0       0    0          0      0   \n",
      "\n",
      "     yuletide  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "..        ...  \n",
      "115         0  \n",
      "116         0  \n",
      "117         0  \n",
      "118         0  \n",
      "119         0  \n",
      "\n",
      "[120 rows x 1569 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a new dataframe containing the BOW outputs and the corresponding words as columns. And print it\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vocabulary)\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well as you see we're still having some issue, we have some tokens that are not words, like '10' or '2000'.\n",
    "\n",
    "To get rid of that, we could use directly regular expressions within the function. Another solution would be to make preprocessing before using the function *CountVectorizer*.\n",
    "\n",
    "For the moment, we won't pay attention to this issue. But if you are curious and have time, you can find on google how to remove those words using the *CountVectorizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to see what are the most used words by Coldplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh\n"
     ]
    }
   ],
   "source": [
    "sum_bow = bow_df.sum()\n",
    "most_used_word = sum_bow.idxmax()\n",
    "print(most_used_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the most used word? Are you surprised?\n",
    "\n",
    "Now make a sort in order to show the 10 most used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most used words by Coldplay:\n",
      "oh      334\n",
      "don     190\n",
      "know    137\n",
      "just    136\n",
      "ll      132\n",
      "come    126\n",
      "yeah    111\n",
      "love     95\n",
      "ooh      95\n",
      "want     86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: print the 10 most used word by Coldplay\n",
    "sum_bow = bow_df.sum()\n",
    "top_10_words = sum_bow.nlargest(10)\n",
    "print(\"Top 10 most used words by Coldplay:\")\n",
    "print(top_10_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is! You know the Coldplay lyrics more than the singers now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
